[{"path":"torch/utils/_dtype_abbrs.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"c4eb9c56671dba774aa09d27887330fc350311fd","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: \"f8e4m3fnuz\",\n    torch.float8_e5m2fnuz: \"f8e5m2fnuz\",\n    torch.float8_e8m0fnu: \"f8e8m0fnu\",\n    torch.float4_e2m1fn_x2: \"f4e2m1fnx2\",\n    torch.complex32: \"c32\",\n    torch.complex64: \"c64\",\n    torch.complex128: \"c128\",","matches":[{"indices":[125,147],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/utils/_dtype_abbrs.py"},{"path":"benchmarks/float8/bench_matmul.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"30ea2eab39eb47fa6345da1997892a7997b7c04b","textMatches":[{"fragment":"        B_hp_t = torch.randn(N, K, device=device)\n\n        if recipe == \"mxfp4_cutlass\":\n            _, A = to_mx(A_hp, torch.float4_e2m1fn_x2, 32)\n            _, Bt = to_mx(B_hp_t, torch.float4_e2m1fn_x2, 32)\n            B = Bt.contiguous().T\n            peak_tops = fp4_peak_tops","matches":[{"indices":[120,142],"text":"torch.float4_e2m1fn_x2"},{"indices":[182,204],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/benchmarks/float8/bench_matmul.py"},{"path":"python/nvfuser/pytorch_utils.py","repository":{"id":"R_kgDOJH2wbw","isFork":false,"isPrivate":false,"nameWithOwner":"NVIDIA/Fuser","url":"https://github.com/NVIDIA/Fuser"},"sha":"0879284975aa788c6bc64ceb25404b4369bc2f4e","textMatches":[{"fragment":"    torch.float8_e4m3fn: DataType.Float8_e4m3fn,\n    torch.float8_e5m2: DataType.Float8_e5m2,\n    torch.float8_e8m0fnu: DataType.Float8_e8m0fnu,\n    # torch.float4_e2m1fn_x2: DataType.Float4_e2m1fn_x2,\n    torch.long: DataType.Int,\n    torch.int: DataType.Int32,\n    torch.bool: DataType.Bool,","matches":[{"indices":[151,173],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/NVIDIA/Fuser/blob/792b0ced69554626b7878208a404a33d809125f0/python/nvfuser/pytorch_utils.py"},{"path":"torch/onnx/ops/_dtype_mappings.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"0023e356d89f1e27659c198877869c030293a660","textMatches":[{"fragment":"    18: torch.float8_e4m3fnuz,  # FLOAT8E4M3FNUZ\n    19: torch.float8_e5m2,  # FLOAT8E5M2\n    20: torch.float8_e5m2fnuz,  # FLOAT8E5M2FNUZ\n    21: torch.uint8,  # UINT4\n    22: torch.uint8,  # INT4\n    23: torch.float4_e2m1fn_x2,  # FLOAT4E2M1\n}","matches":[{"indices":[206,228],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/onnx/ops/_dtype_mappings.py"},{"path":"kernels/gn_kernels/utils.py","repository":{"id":"R_kgDOMXB-QA","isFork":false,"isPrivate":false,"nameWithOwner":"gau-nernst/quantized-training","url":"https://github.com/gau-nernst/quantized-training"},"sha":"82ac9b17a64917cfe0782c5b2343c767ea7477d1","textMatches":[{"fragment":"DTYPE_AMAX_LUT = {\n    torch.float4_e2m1fn_x2: 6.0,\n    torch.float8_e4m3fn: 448.0,","matches":[{"indices":[23,45],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"DTYPE_POW2_AMAX_LUT = {\n    torch.float4_e2m1fn_x2: 4.0,\n    torch.float8_e4m3fn: 256.0,","matches":[{"indices":[28,50],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/gau-nernst/quantized-training/blob/7bca872105cc0aab20fe77c06e8064319fe5b35b/kernels/gn_kernels/utils.py"},{"path":"py/torch_tensorrt/_enums.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkyNDY2MzQzMDY=","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/TensorRT","url":"https://github.com/pytorch/TensorRT"},"sha":"e0a78e1a0b07a70adb2d5864125ca6c654364406","textMatches":[{"fragment":"                return dtype.f8\n            elif t == torch.float4_e2m1fn_x2:\n                return dtype.f4","matches":[{"indices":[54,76],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"            elif self == dtype.f4:\n                return torch.float4_e2m1fn_x2\n            elif self == dtype.f16:","matches":[{"indices":[58,80],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/TensorRT/blob/ab9e3093bbb4dffe7366c2bad1dc383b6b773651/py/torch_tensorrt/_enums.py"},{"path":"modelling/mx.py","repository":{"id":"R_kgDONQ7Vpw","isFork":false,"isPrivate":false,"nameWithOwner":"gau-nernst/rectified-flow","url":"https://github.com/gau-nernst/rectified-flow"},"sha":"2f895f6b83d787689a12d967b02a2a1458c62361","textMatches":[{"fragment":"        xq, xs = quantize_mx(x_2d, self.wq.dtype, compute_scale_method=self.compute_scale_method)\n        xs = pack_block_scales_nv(xs)\n\n        if self.wq.dtype == torch.float4_e2m1fn_x2:\n            out = mxfp4_mm(xq, self.wq.T, xs, self.ws, self.bias)\n        else:\n            out = torch._scaled_mm(xq, self.wq.T, xs, self.ws, self.bias, out_dtype=torch.bfloat16)","matches":[{"indices":[165,187],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/gau-nernst/rectified-flow/blob/a20ab5622b55fb063503646acdf24fa86df3865b/modelling/mx.py"},{"path":"torch/_meta_registrations.py","repository":{"id":"R_kgDOOdu8Yw","isFork":false,"isPrivate":false,"nameWithOwner":"Divigroup-RAP/PYTORCH","url":"https://github.com/Divigroup-RAP/PYTORCH"},"sha":"dab0e92558fccee6ca09e22b480d8adadec24fc7","textMatches":[{"fragment":"            torch.float8_e5m2,\n            torch.float8_e4m3fnuz,\n            torch.float8_e5m2fnuz,\n            torch.float4_e2m1fn_x2,\n        )\n\n    torch._check(","matches":[{"indices":[113,135],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/Divigroup-RAP/PYTORCH/blob/ca017bbcb87e44a379c9f6beb3bf68a8177e1872/torch/_meta_registrations.py"},{"path":"data/tagged/pytorch/pytorch_2025.csv","repository":{"id":"R_kgDOOYtgOg","isFork":false,"isPrivate":false,"nameWithOwner":"776A64/research","url":"https://github.com/776A64/research"},"sha":"5bf7844cbe9f1a3ac06176aa40b24f8969443dc3","textMatches":[{"fragment":"\"bug\",\"模型量化训练过程存在问题\",\"量化模型性能明显下降\",https://github.com/pytorch/pytorch/issues/150746\n\"bug\",\"该问题单的根本原因是缺少对8位矩阵乘法动态量化的支持\",\"用户需求动态量化8位矩阵乘法支持\",https://github.com/pytorch/pytorch/issues/149500\n\"bug\",\"模型在导出到ONNX时无法保持动态批处理大小。在使用torch.onnx.export和启用dynamo时，尝试将PARSeq模型（基于Transformer的场景文本识别模型）导出到ONNX时遇到问题。尽管可以成功将固定批处理大小导出，但无法成功使用动态形状。\",\"在使用导出的ONNX模型进行推断时，例如批处理大小为8，会导致如下错误：`onnxruntime.capi.onnxruntime_pybind11_state`。\",https://github.com/pytorch/pytorch/issues/148886\n\"bug\",\"根因可能是缺少支持`torch.float4_e2m1fn_x2`的适配性代码\",\"症状描述是需要重做先前的提交以解决rebase冲突。\",https://github.com/pytorch/pytorch/issues/148791\n\"bug\",\"导致 quantization 失败\",\"出现了不应该存在的 onnx::Neg_2 输入\",https://github.com/pytorch/pytorch/issues/148655\n\"bug\",\"问题的根因是在AArch64平台上由于冗余的权重预转置和减少导致qlinear_static的高开销。\",\"问题的症状描述是对AArch64上的qlinear_static存在高开销。\",https://github.com/pytorch/pytorch/issues/148586\n\"bug\",\"当前qlinear_dynamic路径因为状态式oneDNN API与有状态的ACL低精度GEMM API之间的API摩擦导致高开销\",\"所以ACL的lowp_gemm对象缓存信息如权重缩减或者优化过的权重量展示出延迟高的现象\",https://github.com/pytorch/pytorch/issues/148583","matches":[{"indices":[849,871],"text":"linear_dynamic路径因为状态式o"}],"property":"content","type":"FileContent"}],"url":"https://github.com/776A64/research/blob/4534201e91635694127e53af28f1fb3268b425fe/data/tagged/pytorch/pytorch_2025.csv"},{"path":"torch/_meta_registrations.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"aaab720456ad7aa6b4645f79a41be870e0e4384e","textMatches":[{"fragment":"            torch.float8_e5m2,\n            torch.float8_e4m3fnuz,\n            torch.float8_e5m2fnuz,\n            torch.float4_e2m1fn_x2,\n        )\n\n    torch._check(","matches":[{"indices":[113,135],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/_meta_registrations.py"},{"path":"torchao/prototype/mx_formats/README.md","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"587d81f6a6e05f9fa108470ae6890e52558b661d","textMatches":[{"fragment":"from torchao.prototype.mx_formats.constants import DTYPE_FP6_E2M3, DTYPE_FP6_E3M2\nx = torch.randn(32, 32, device='cuda')\n\n# elem_dtype can be torch.float8_e4m3fn, torch.float8_e5m2, DTYPE_FP6_E2M3, DTYPE_FP6_E3M2, torch.float4_e2m1fn_x2\nelem_dtype = torch.float8_e4m3fn\n\n# high precision to MX, block size defaults to 32","matches":[{"indices":[214,236],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/README.md"},{"path":"torch/fx/graph.py","repository":{"id":"R_kgDOO_BySw","isFork":false,"isPrivate":false,"nameWithOwner":"glen-amd/rocm_pytorch","url":"https://github.com/glen-amd/rocm_pytorch"},"sha":"75c0eb8081fb6aca37d15e15129ad2a10c055ff1","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: \"f8e4m3fnuz\",\n    torch.float8_e5m2fnuz: \"f8e5m2fnuz\",\n    torch.float8_e8m0fnu: \"f8e8m0fnu\",\n    torch.float4_e2m1fn_x2: \"f4e2m1fnx2\",\n    torch.complex32: \"c32\",\n    torch.complex64: \"c64\",\n    torch.complex128: \"c128\",","matches":[{"indices":[125,147],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/glen-amd/rocm_pytorch/blob/0a6e1d6b9bf78d690a812e4334939e7701bfa794/torch/fx/graph.py"},{"path":"python/nvfuser/testing/utils.py","repository":{"id":"R_kgDOJH2wbw","isFork":false,"isPrivate":false,"nameWithOwner":"NVIDIA/Fuser","url":"https://github.com/NVIDIA/Fuser"},"sha":"d2d71f69aa62fae48ec2bc03d6f2373d6deacb2f","textMatches":[{"fragment":"    torch.float8_e4m3fn: \"float8_e4m3fn\",\n    torch.float8_e5m2: \"float8_e5m2\",\n    torch.float8_e8m0fnu: \"float8_e8m0fnu\",\n    # torch.float4_e2m1fn_x2: \"float4_e2m1fn_x2\",\n    torch.bfloat16: \"bfloat16\",\n    torch.float16: \"float16\",\n    torch.float32: \"float32\",","matches":[{"indices":[130,152],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/NVIDIA/Fuser/blob/792b0ced69554626b7878208a404a33d809125f0/python/nvfuser/testing/utils.py"},{"path":"kernels/gn_kernels/cutlass_mm.py","repository":{"id":"R_kgDOMXB-QA","isFork":false,"isPrivate":false,"nameWithOwner":"gau-nernst/quantized-training","url":"https://github.com/gau-nernst/quantized-training"},"sha":"f75787746e3676799b3c6d0a23e3c9bcd59190c8","textMatches":[{"fragment":"\n\ndef mxfp4_mm(A: Tensor, B: Tensor, scale_A: Tensor, scale_B: Tensor, bias: Tensor | None = None) -> Tensor:\n    assert A.ndim == 2 and A.dtype is torch.float4_e2m1fn_x2 and A.is_contiguous()\n    assert B.ndim == 2 and B.dtype is torch.float4_e2m1fn_x2 and B.T.is_contiguous()\n    assert A.shape[1] == B.shape[0]\n    assert scale_A.dtype == torch.float8_e8m0fnu","matches":[{"indices":[148,170],"text":"torch.float4_e2m1fn_x2"},{"indices":[231,253],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/gau-nernst/quantized-training/blob/7bca872105cc0aab20fe77c06e8064319fe5b35b/kernels/gn_kernels/cutlass_mm.py"},{"path":"docs/source/tensor_attributes.rst","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"eda8dbce234ce1fee21ba7121f7dd609ff8a9c16","textMatches":[{"fragment":"``torch.float8_e4m3fnuz`` [shell]_, [1]_   8-bit floating point, S-E-M 1-4-3, from https://arxiv.org/pdf/2206.02915\n``torch.float8_e5m2fnuz`` [shell]_, [1]_   8-bit floating point, S-E-M 1-5-2, from https://arxiv.org/pdf/2206.02915\n``torch.float8_e8m0fnu`` [shell]_, [1]_    8-bit floating point, S-E-M 0-8-0, from https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf\n``torch.float4_e2m1fn_x2`` [shell]_, [1]_  packed 4-bit floating point, S-E-M 1-2-1, from https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf\n=========================================  ===============================\n\n**Integer dtypes**","matches":[{"indices":[403,425],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/docs/source/tensor_attributes.rst"},{"path":"torch/onnx/_internal/exporter/_type_casting.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"ac4538a4cfb74571b29ef0849c01d293cdd0c905","textMatches":[{"fragment":"    \"\"\"Convert a float4x2 tensor to unpacked uint8 np array.\"\"\"\n    assert tensor.dtype == torch.float4_e2m1fn_x2\n    data = tensor.view(torch.uint8).numpy(force=True).flatten()","matches":[{"indices":[91,113],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    \"\"\"\n    assert tensor.dtype == torch.float4_e2m1fn_x2\n    return (*tensor.shape, 2)","matches":[{"indices":[35,57],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/onnx/_internal/exporter/_type_casting.py"},{"path":"benchmark_mm.py","repository":{"id":"R_kgDOMXB-QA","isFork":false,"isPrivate":false,"nameWithOwner":"gau-nernst/quantized-training","url":"https://github.com/gau-nernst/quantized-training"},"sha":"c6cbbb3c5fd66c904a0688be8785f1902d227dc2","textMatches":[{"fragment":"        # FP4\n        if COMPUTE_CAPABILITY == (12, 0) and not args.a_column_major and args.b_column_major:\n            A_fp4 = torch.randint(255, size=(M, K // 2), dtype=torch.uint8).view(torch.float4_e2m1fn_x2)\n            B_fp4 = torch.randint(255, size=(N, K // 2), dtype=torch.uint8).view(torch.float4_e2m1fn_x2).T\n\n            scale_A_mx = torch.randn(M, K // 32).to(torch.float8_e8m0fnu)\n            scale_B_mx = torch.randn(N, K // 32).to(torch.float8_e8m0fnu)","matches":[{"indices":[189,211],"text":"torch.float4_e2m1fn_x2"},{"indices":[294,316],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/gau-nernst/quantized-training/blob/7bca872105cc0aab20fe77c06e8064319fe5b35b/benchmark_mm.py"},{"path":"src/mindtorch/storage.py","repository":{"id":"R_kgDOIr7rSQ","isFork":false,"isPrivate":false,"nameWithOwner":"ms-ecosystem/easyms","url":"https://github.com/ms-ecosystem/easyms"},"sha":"c2789cdb13c983bdf5ec8cd85a6ea09bcfb37af9","textMatches":[{"fragment":"        mindtorch.float8_e5m2fnuz,\n        mindtorch.float8_e4m3fnuz,\n        mindtorch.float8_e8m0fnu,\n        mindtorch.float4_e2m1fn_x2,\n        mindtorch.bits8,\n        mindtorch.bits16,\n        mindtorch.bits1x8,","matches":[{"indices":[116,138],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ms-ecosystem/easyms/blob/8a8ae168a68f48bcbfb324dfc0ca60aad7f84aa1/src/mindtorch/storage.py"},{"path":"torchao/prototype/mx_formats/config.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"525bf21fc61f60e8a6add9a1ce2067893b0f8553","textMatches":[{"fragment":"        )\n        valid_dtypes = [torch.float8_e4m3fn, torch.float4_e2m1fn_x2]\n        assert elem_dtype in valid_dtypes, (","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        )\n        valid_dtypes = [torch.float8_e4m3fn, torch.float4_e2m1fn_x2]\n        assert elem_dtype in valid_dtypes, (","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/config.py"},{"path":"torch/_meta_registrations.py","repository":{"id":"R_kgDOO_BySw","isFork":false,"isPrivate":false,"nameWithOwner":"glen-amd/rocm_pytorch","url":"https://github.com/glen-amd/rocm_pytorch"},"sha":"8ed304872248053d2a82e848d63de1cda629a842","textMatches":[{"fragment":"            torch.float8_e5m2,\n            torch.float8_e4m3fnuz,\n            torch.float8_e5m2fnuz,\n            torch.float4_e2m1fn_x2,\n        )\n\n    torch._check(","matches":[{"indices":[113,135],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/glen-amd/rocm_pytorch/blob/0a6e1d6b9bf78d690a812e4334939e7701bfa794/torch/_meta_registrations.py"},{"path":"torch/_tensor_str.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"a03c4efc15b7eb8fa40983ca612ce0709b4f3361","textMatches":[{"fragment":"                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            if tensor.dtype == torch.float4_e2m1fn_x2:  # type: ignore[attr-defined]\n                # torch.float4_e2m1fn_x2 is special and does not support the casts necessary\n                # to print it, we choose to display the uint8 representation here for\n                # convenience of being able to print a tensor.","matches":[{"indices":[115,137],"text":"torch.float4_e2m1fn_x2"},{"indices":[187,209],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/_tensor_str.py"},{"path":"torch/fx/graph.py","repository":{"id":"R_kgDOOdu8Yw","isFork":false,"isPrivate":false,"nameWithOwner":"Divigroup-RAP/PYTORCH","url":"https://github.com/Divigroup-RAP/PYTORCH"},"sha":"4a156dba04630072040a8fc575e8a2d57b19d774","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: \"f8e4m3fnuz\",\n    torch.float8_e5m2fnuz: \"f8e5m2fnuz\",\n    torch.float8_e8m0fnu: \"f8e8m0fnu\",\n    torch.float4_e2m1fn_x2: \"f4e2m1fnx2\",\n    torch.complex32: \"c32\",\n    torch.complex64: \"c64\",\n    torch.complex128: \"c128\",","matches":[{"indices":[125,147],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/Divigroup-RAP/PYTORCH/blob/ca017bbcb87e44a379c9f6beb3bf68a8177e1872/torch/fx/graph.py"},{"path":"torch/_tensor_str.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"921e97be233ad18e6beea5ee50f4b809506c60ea","textMatches":[{"fragment":"                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            if tensor.dtype == torch.float4_e2m1fn_x2:  # type: ignore[attr-defined]\n                # torch.float4_e2m1fn_x2 is special and does not support the casts necessary\n                # to print it, we choose to display the uint8 representation here for\n                # convenience of being able to print a tensor.","matches":[{"indices":[115,137],"text":"torch.float4_e2m1fn_x2"},{"indices":[187,209],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/_tensor_str.py"},{"path":"torch/onnx/ops/_symbolic_impl.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"5a5ede4d65d7a0ccd9de73f18d5dea0f8977c74a","textMatches":[{"fragment":"    20: torch.float8_e5m2fnuz,  # FLOAT8E5M2FNUZ\n    21: torch.uint8,  # UINT4\n    22: torch.uint8,  # INT4\n    23: torch.float4_e2m1fn_x2,  # FLOAT4E2M1\n}\n\n_INT_TYPE = \"i\"","matches":[{"indices":[116,138],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/onnx/ops/_symbolic_impl.py"},{"path":"torch/onnx/ops/__init__.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"3bdcd417e1acd6b502ef7071289ebb6d913ec2fc","textMatches":[{"fragment":"    torch.float8_e5m2fnuz: 20,  # FLOAT8E5M2FNUZ\n    # 21 = UINT4\n    # 22 = INT4\n    torch.float4_e2m1fn_x2: 23,  # FLOAT4E2M1\n}\n\n","matches":[{"indices":[86,108],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/onnx/ops/__init__.py"},{"path":"torch/onnx/_internal/exporter/_core.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"c6a84c448587e22f2c16fcab01b49deb781113aa","textMatches":[{"fragment":"    torch.float8_e5m2fnuz: ir.DataType.FLOAT8E5M2FNUZ,\n    torch.float4_e2m1fn_x2: ir.DataType.FLOAT4E2M1,\n    torch.int16: ir.DataType.INT16,","matches":[{"indices":[59,81],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # Pass the tensor as the raw data to ir.Tensor's constructor\n        if tensor.dtype == torch.float4_e2m1fn_x2:\n            # Change the shape to the unpacked shape","matches":[{"indices":[96,118],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/onnx/_internal/exporter/_core.py"},{"path":"torch/onnx/_internal/exporter/_core.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"fcaa63f04d470ea8310a19d48c63e766e4c656d9","textMatches":[{"fragment":"    torch.float8_e5m2fnuz: ir.DataType.FLOAT8E5M2FNUZ,\n    torch.float4_e2m1fn_x2: ir.DataType.FLOAT4E2M1,\n    torch.int16: ir.DataType.INT16,","matches":[{"indices":[59,81],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # Pass the tensor as the raw data to ir.Tensor's constructor\n        if tensor.dtype == torch.float4_e2m1fn_x2:\n            # Change the shape to the unpacked shape","matches":[{"indices":[96,118],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/onnx/_internal/exporter/_core.py"},{"path":"torch/onnx/_internal/exporter/_dispatching.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"141cb76deacd1cab7d3ebe79045fce42227b8e1e","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: ir.DataType.FLOAT8E4M3FNUZ,\n    torch.float8_e5m2: ir.DataType.FLOAT8E5M2,\n    torch.float8_e5m2fnuz: ir.DataType.FLOAT8E5M2FNUZ,\n    torch.float4_e2m1fn_x2: ir.DataType.FLOAT4E2M1,\n    torch.int16: ir.DataType.INT16,\n    torch.int32: ir.DataType.INT32,\n    torch.int64: ir.DataType.INT64,","matches":[{"indices":[161,183],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/onnx/_internal/exporter/_dispatching.py"},{"path":"torch/storage.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"e651bc9d16eb181bc61903da197ce7e6ce3395bd","textMatches":[{"fragment":"        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fnuz,\n        torch.float8_e8m0fnu,\n        torch.float4_e2m1fn_x2,\n        torch.bits8,\n        torch.bits16,\n        torch.bits1x8,","matches":[{"indices":[100,122],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/storage.py"},{"path":"torchao/prototype/mx_formats/constants.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"ffac3b1d5f2970db14b98400c69d399d63504b13","textMatches":[{"fragment":"SUPPORTED_ELEM_DTYPES = (\n    SUPPORTED_ELEM_DTYPES + [torch.float4_e2m1fn_x2]\n    if TORCH_VERSION_AT_LEAST_2_8","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"if TORCH_VERSION_AT_LEAST_2_8:\n    DTYPE_TO_SHORT_STR[torch.float4_e2m1fn_x2] = \"f4e2m1\"\n","matches":[{"indices":[54,76],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/constants.py"},{"path":"torchao/prototype/mx_formats/mx_tensor.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"e98878af7774307b80f6e12e4d5ed008e083daae","textMatches":[{"fragment":"        max_pos = F6_E3M2_MAX\n    elif elem_dtype == torch.float4_e2m1fn_x2:\n        target_max_pow2 = F4_E2M1_MAX_POW2","matches":[{"indices":[53,75],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        data_lp = data_lp.reshape(orig_shape)\n    elif elem_dtype == torch.float4_e2m1fn_x2:\n        # can't reshape at the end without handling it in the packing code,","matches":[{"indices":[69,91],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/mx_tensor.py"},{"path":"torchao/prototype/mx_formats/nvfp4_tensor.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"1545b1bc94994f6d7626c97f58dd3a355b6b650c","textMatches":[{"fragment":"    should_add_bias_separately = (scale_result is not None) and (bias is not None)\n\n    result = torch._scaled_mm(\n        a._data.view(torch.float4_e2m1fn_x2),\n        b._data.view(torch.float4_e2m1fn_x2),\n        a_scale_blocked.view(torch.float8_e4m3fn),\n        b_scale_blocked.view(torch.float8_e4m3fn),","matches":[{"indices":[136,158],"text":"torch.float4_e2m1fn_x2"},{"indices":[182,204],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/nvfp4_tensor.py"},{"path":"torch/storage.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"824a29af59702bb203e189b29ba34a239a22ba63","textMatches":[{"fragment":"        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fnuz,\n        torch.float8_e8m0fnu,\n        torch.float4_e2m1fn_x2,\n        torch.bits8,\n        torch.bits16,\n        torch.bits1x8,","matches":[{"indices":[100,122],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/storage.py"},{"path":"torchao/prototype/mx_formats/fp_format_spec.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"d89a3ad2a9b2fcdbbc72b355209fa08314551258","textMatches":[{"fragment":"\n    if dtype == torch.float4_e2m1fn_x2:\n        results = float4_e2m1_interesting_values","matches":[{"indices":[17,39],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        DTYPE_FP6_E2M3,\n        torch.float4_e2m1fn_x2,\n    ):","matches":[{"indices":[32,54],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/fp_format_spec.py"},{"path":"torch/onnx/_internal/exporter/_type_casting.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"7f2141fe577e64a8d98b6f44100971a03338d8d7","textMatches":[{"fragment":"    \"\"\"Convert a float4x2 tensor to unpacked uint8 np array.\"\"\"\n    assert tensor.dtype == torch.float4_e2m1fn_x2\n    data = tensor.view(torch.uint8).numpy(force=True).flatten()","matches":[{"indices":[91,113],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    \"\"\"\n    assert tensor.dtype == torch.float4_e2m1fn_x2\n    return (*tensor.shape[:-1], tensor.shape[-1] * 2)","matches":[{"indices":[35,57],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/onnx/_internal/exporter/_type_casting.py"},{"path":"torch/onnx/ops/__init__.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"3bbd3a64327ba0fd4af80a911260c5ee8f922238","textMatches":[{"fragment":"    torch.float8_e5m2fnuz: 20,  # FLOAT8E5M2FNUZ\n    # 21 = UINT4\n    # 22 = INT4\n    torch.float4_e2m1fn_x2: 23,  # FLOAT4E2M1\n}\n\n","matches":[{"indices":[86,108],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/onnx/ops/__init__.py"},{"path":"torchao/prototype/mx_formats/mx_ops.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"c7e673dc377007107e1f084b3d1a793c7cb0336c","textMatches":[{"fragment":"                out_dtype=torch.bfloat16,\n            )\n        else:\n            assert a._elem_dtype == torch.float4_e2m1fn_x2\n            assert b._elem_dtype == torch.float4_e2m1fn_x2\n            assert gemm_choice is MXGemmKernelChoice.CUTLASS, \"unsupported\"\n            # FP4 operations","matches":[{"indices":[106,128],"text":"torch.float4_e2m1fn_x2"},{"indices":[165,187],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/mx_ops.py"},{"path":"bindings/python/tests/test_pt_comparison.py","repository":{"id":"R_kgDOIDBDJA","isFork":false,"isPrivate":false,"nameWithOwner":"huggingface/safetensors","url":"https://github.com/huggingface/safetensors"},"sha":"441fb3519ea36581ee263c87011f1468ed115688","textMatches":[{"fragment":"        test1 = torch.tensor([0.0], dtype=torch.float8_e8m0fnu)\n        test2 = torch.empty(2, 2, device=\"cpu\", dtype=torch.float4_e2m1fn_x2)\n        data = {","matches":[{"indices":[118,140],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        self.assertEqual(reloaded[\"test1\"], test1)\n        self.assertEqual(reloaded[\"test2\"].dtype, torch.float4_e2m1fn_x2)\n        # TODO RuntimeError: \"eq_cpu\" not implemented for 'Float4_e2m1fn_x2'","matches":[{"indices":[101,123],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/huggingface/safetensors/blob/6544bf21bfa416999ea4c304d11e1d2b9379518d/bindings/python/tests/test_pt_comparison.py"},{"path":"torchao/prototype/mx_formats/benchmarks/bench_qdq.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"ca0b926ce5dfec8a66415affef106c5f652eebd9","textMatches":[{"fragment":"            )\n\n            if (\n                elem_dtype != torch.float4_e2m1fn_x2\n                and use_fp4_custom_triton_dequant_kernel  # noqa: E501\n            ):\n                # custom_triton_kernels only works for fp4","matches":[{"indices":[62,84],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/torchao/prototype/mx_formats/benchmarks/bench_qdq.py"},{"path":"torch/_meta_registrations.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"7f2bcfaa4720ee27e4071ce0445e8af4f40ffffb","textMatches":[{"fragment":"            torch.float8_e5m2,\n            torch.float8_e4m3fnuz,\n            torch.float8_e5m2fnuz,\n            torch.float4_e2m1fn_x2,\n        )\n\n    torch._check(","matches":[{"indices":[113,135],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/torch/_meta_registrations.py"},{"path":"torch/_meta_registrations.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"c590e4d0dfbe77a96aa5455ac891c637d027e6b4","textMatches":[{"fragment":"            torch.float8_e5m2,\n            torch.float8_e4m3fnuz,\n            torch.float8_e5m2fnuz,\n            torch.float4_e2m1fn_x2,\n        )\n\n    torch._check(","matches":[{"indices":[113,135],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/_meta_registrations.py"},{"path":"pytorch/test/test_matmul_cuda.py","repository":{"id":"R_kgDOOsEsGg","isFork":false,"isPrivate":false,"nameWithOwner":"netanelcyber/zenday1","url":"https://github.com/netanelcyber/zenday1"},"sha":"33055b66011f452afc0d1c164b4da2536c4e1492","textMatches":[{"fragment":"F8E8M0_EXP_BIAS = 127\n# exponent and mantissa bits of `torch.float4_e2m1fn_x2`\nFP4_EBITS, FP4_MBITS = 2, 1","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    x = pack_uint4(x)\n    x = x.view(torch.float4_e2m1fn_x2)\n    return x","matches":[{"indices":[37,59],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/netanelcyber/zenday1/blob/59eaf2b345eda98ad42bb3fc10c0fdbd7f45215c/pytorch/test/test_matmul_cuda.py"},{"path":"test/test_matmul_cuda.py","repository":{"id":"R_kgDOOdu8Yw","isFork":false,"isPrivate":false,"nameWithOwner":"Divigroup-RAP/PYTORCH","url":"https://github.com/Divigroup-RAP/PYTORCH"},"sha":"17ece41af239bd10cc541ea4304030ba35bbb600","textMatches":[{"fragment":"F8E8M0_EXP_BIAS = 127\n# exponent and mantissa bits of `torch.float4_e2m1fn_x2`\nFP4_EBITS, FP4_MBITS = 2, 1","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    x = pack_uint4(x)\n    x = x.view(torch.float4_e2m1fn_x2)\n    return x","matches":[{"indices":[37,59],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/Divigroup-RAP/PYTORCH/blob/ca017bbcb87e44a379c9f6beb3bf68a8177e1872/test/test_matmul_cuda.py"},{"path":"test/test_matmul_cuda.py","repository":{"id":"R_kgDOO_BySw","isFork":false,"isPrivate":false,"nameWithOwner":"glen-amd/rocm_pytorch","url":"https://github.com/glen-amd/rocm_pytorch"},"sha":"0a6aa9234d4c7c25254e0e9957ca50a822f3c5aa","textMatches":[{"fragment":"F8E8M0_EXP_BIAS = 127\n# exponent and mantissa bits of `torch.float4_e2m1fn_x2`\nFP4_EBITS, FP4_MBITS = 2, 1","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    x = pack_uint4(x)\n    x = x.view(torch.float4_e2m1fn_x2)\n    return x","matches":[{"indices":[37,59],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/glen-amd/rocm_pytorch/blob/0a6e1d6b9bf78d690a812e4334939e7701bfa794/test/test_matmul_cuda.py"},{"path":"test/onnx/exporter/test_core.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"7a2eaaf1a82805906fd3340bae011f8cc7e5cb47","textMatches":[{"fragment":"            (torch.uint8, np.uint8),\n            (torch.float4_e2m1fn_x2, ml_dtypes.float4_e2m1fn),\n        ],","matches":[{"indices":[50,72],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    def test_numpy_returns_correct_dtype(self, dtype: torch.dtype, np_dtype):\n        if dtype == torch.float4_e2m1fn_x2:\n            tensor = _core.TorchTensor(torch.tensor([1], dtype=torch.uint8).view(dtype))","matches":[{"indices":[98,120],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/test/onnx/exporter/test_core.py"},{"path":"test/test_matmul_cuda.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"e8b4d9092cdd04c10837ddc4aeda6d2120f10aeb","textMatches":[{"fragment":"F8E8M0_EXP_BIAS = 127\n# exponent and mantissa bits of `torch.float4_e2m1fn_x2`\nFP4_EBITS, FP4_MBITS = 2, 1","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    x = pack_uint4(x)\n    x = x.view(torch.float4_e2m1fn_x2)\n    return x","matches":[{"indices":[37,59],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/test/test_matmul_cuda.py"},{"path":"test/onnx/exporter/test_small_models_e2e.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"9b90e2f878459f17dfe71529d0f9c8d86bd91544","textMatches":[{"fragment":"    def test_float4_support(self):\n        class Float4Module(torch.nn.Module):\n            def forward(self):\n                return torch.empty([1], dtype=torch.float4_e2m1fn_x2)\n\n        onnx_program = self.export(Float4Module(), optimize=False)\n        output = onnx_program.model.graph.outputs[0]","matches":[{"indices":[157,179],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/test/onnx/exporter/test_small_models_e2e.py"},{"path":"test/quantization/core/experimental/test_floatx.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"01f59d4765b7b258e7506be7c7b7ba339666c6ff","textMatches":[{"fragment":"        # can create a tensor of dtype float4\n        x1 = torch.empty(4096, 4096, device=device, dtype=torch.float4_e2m1fn_x2)\n","matches":[{"indices":[104,126],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # can view uint8 as float4_e2m1fn_x2\n        x2.view(torch.float4_e2m1fn_x2)\n","matches":[{"indices":[61,83],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/test/quantization/core/experimental/test_floatx.py"},{"path":"test/onnx/exporter/test_small_models_e2e.py","repository":{"id":"MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/pytorch","url":"https://github.com/pytorch/pytorch"},"sha":"f774104af1871a6fd32314c74ea603f81e97264b","textMatches":[{"fragment":"    def test_float4_support(self):\n        class Float4Module(torch.nn.Module):\n            def forward(self):\n                return torch.empty([1], dtype=torch.float4_e2m1fn_x2)\n\n        onnx_program = self.export(Float4Module(), optimize=False)\n        output = onnx_program.model.graph.outputs[0]","matches":[{"indices":[157,179],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch/blob/84c588e5eada9e7921608065edc444a15c22cb1c/test/onnx/exporter/test_small_models_e2e.py"},{"path":"test/test_matmul_cuda.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"593c78f74d41cc8e5caa2fe972a96b608eb18285","textMatches":[{"fragment":"F8E8M0_EXP_BIAS = 127\n# exponent and mantissa bits of `torch.float4_e2m1fn_x2`\nFP4_EBITS, FP4_MBITS = 2, 1","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    x = pack_uint4(x)\n    x = x.view(torch.float4_e2m1fn_x2)\n    return x","matches":[{"indices":[37,59],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/test/test_matmul_cuda.py"},{"path":"test/prototype/mx_formats/test_mx_linear.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"4e24cfc48278e6fa9c9e0f80892f719624cbed60","textMatches":[{"fragment":"        (torch.float8_e4m3fn, torch.float8_e4m3fn, torch.float8_e4m3fn),\n        (DTYPE_FP6_E3M2, DTYPE_FP6_E3M2, DTYPE_FP6_E3M2),\n        (DTYPE_FP6_E2M3, DTYPE_FP6_E2M3, DTYPE_FP6_E2M3),\n        (torch.float4_e2m1fn_x2, torch.float4_e2m1fn_x2, torch.float4_e2m1fn_x2),\n        # only test one type of mixed-dtype overrides, to save testing time\n        (torch.float8_e4m3fn, torch.float4_e2m1fn_x2, torch.float4_e2m1fn_x2),\n    ]","matches":[{"indices":[198,220],"text":"torch.float4_e2m1fn_x2"},{"indices":[222,244],"text":"torch.float4_e2m1fn_x2"},{"indices":[246,268],"text":"torch.float4_e2m1fn_x2"},{"indices":[377,399],"text":"torch.float4_e2m1fn_x2"},{"indices":[401,423],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/test/prototype/mx_formats/test_mx_linear.py"},{"path":"test/prototype/mx_formats/test_mx_mm.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"46380cfb554651eb0e0c2c21a01722794aa3db62","textMatches":[{"fragment":"    a = torch.rand((M, K), dtype=dtype, device=device)\n    b = torch.rand((N, K), dtype=dtype, device=device)\n\n    fmt = torch.float8_e4m3fn if format == \"fp8\" else torch.float4_e2m1fn_x2\n    mx_func = (\n        partial(torch._scaled_mm, out_dtype=torch.bfloat16)\n        if format == \"fp8\"","matches":[{"indices":[165,187],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/test/prototype/mx_formats/test_mx_mm.py"},{"path":"test/prototype/mx_formats/test_kernels.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"d649b2e04ab28605cd14fe96676c847751b2ddfb","textMatches":[{"fragment":"    mxtensor_ref = MXTensor.to_mx(\n        orig_vals, block_size=32, elem_dtype=torch.float4_e2m1fn_x2\n    )","matches":[{"indices":[80,102],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        block_size=32,\n        elem_dtype=torch.float4_e2m1fn_x2,\n        use_fp4_custom_triton_dequant_kernel=True,","matches":[{"indices":[42,64],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/test/prototype/mx_formats/test_kernels.py"},{"path":"test/prototype/mx_formats/test_mx_tensor.py","repository":{"id":"R_kgDOKo_lrg","isFork":false,"isPrivate":false,"nameWithOwner":"pytorch/ao","url":"https://github.com/pytorch/ao"},"sha":"3c4dc7c7b6326aa47481bc8d5520829674be61f0","textMatches":[{"fragment":"            data_bits = pack_uint6(data_bits)\n    elif elem_dtype == torch.float4_e2m1fn_x2:\n        data_bits = torch.tensor(","matches":[{"indices":[69,91],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    \"\"\"\n    if B == 1 and elem_dtype == torch.float4_e2m1fn_x2:\n        pytest.skip(\"unsupported configuration\")","matches":[{"indices":[40,62],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/ao/blob/994a4ba6c869854fcaa6ca7e118fcbd75e6c28cc/test/prototype/mx_formats/test_mx_tensor.py"},{"path":"torch/utils/_dtype_abbrs.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"c4eb9c56671dba774aa09d27887330fc350311fd","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: \"f8e4m3fnuz\",\n    torch.float8_e5m2fnuz: \"f8e5m2fnuz\",\n    torch.float8_e8m0fnu: \"f8e8m0fnu\",\n    torch.float4_e2m1fn_x2: \"f4e2m1fnx2\",\n    torch.complex32: \"c32\",\n    torch.complex64: \"c64\",\n    torch.complex128: \"c128\",","matches":[{"indices":[125,147],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/utils/_dtype_abbrs.py"},{"path":"torch/utils/_dtype_abbrs.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"c4eb9c56671dba774aa09d27887330fc350311fd","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: \"f8e4m3fnuz\",\n    torch.float8_e5m2fnuz: \"f8e5m2fnuz\",\n    torch.float8_e8m0fnu: \"f8e8m0fnu\",\n    torch.float4_e2m1fn_x2: \"f4e2m1fnx2\",\n    torch.complex32: \"c32\",\n    torch.complex64: \"c64\",\n    torch.complex128: \"c128\",","matches":[{"indices":[125,147],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/utils/_dtype_abbrs.py"},{"path":"torch/onnx/ops/_dtype_mappings.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"0023e356d89f1e27659c198877869c030293a660","textMatches":[{"fragment":"    18: torch.float8_e4m3fnuz,  # FLOAT8E4M3FNUZ\n    19: torch.float8_e5m2,  # FLOAT8E5M2\n    20: torch.float8_e5m2fnuz,  # FLOAT8E5M2FNUZ\n    21: torch.uint8,  # UINT4\n    22: torch.uint8,  # INT4\n    23: torch.float4_e2m1fn_x2,  # FLOAT4E2M1\n}","matches":[{"indices":[206,228],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/onnx/ops/_dtype_mappings.py"},{"path":"pytorch/torch/fx/graph.py","repository":{"id":"R_kgDOOsEsGg","isFork":false,"isPrivate":false,"nameWithOwner":"netanelcyber/zenday1","url":"https://github.com/netanelcyber/zenday1"},"sha":"75c0eb8081fb6aca37d15e15129ad2a10c055ff1","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: \"f8e4m3fnuz\",\n    torch.float8_e5m2fnuz: \"f8e5m2fnuz\",\n    torch.float8_e8m0fnu: \"f8e8m0fnu\",\n    torch.float4_e2m1fn_x2: \"f4e2m1fnx2\",\n    torch.complex32: \"c32\",\n    torch.complex64: \"c64\",\n    torch.complex128: \"c128\",","matches":[{"indices":[125,147],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/netanelcyber/zenday1/blob/59eaf2b345eda98ad42bb3fc10c0fdbd7f45215c/pytorch/torch/fx/graph.py"},{"path":"TruthGPT/Without-Framework/Production/pytorch-main/torch/fx/graph.py","repository":{"id":"R_kgDOJBRaWQ","isFork":false,"isPrivate":false,"nameWithOwner":"OpenBlatam/TruthGPT-chatGPT","url":"https://github.com/OpenBlatam/TruthGPT-chatGPT"},"sha":"75c0eb8081fb6aca37d15e15129ad2a10c055ff1","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: \"f8e4m3fnuz\",\n    torch.float8_e5m2fnuz: \"f8e5m2fnuz\",\n    torch.float8_e8m0fnu: \"f8e8m0fnu\",\n    torch.float4_e2m1fn_x2: \"f4e2m1fnx2\",\n    torch.complex32: \"c32\",\n    torch.complex64: \"c64\",\n    torch.complex128: \"c128\",","matches":[{"indices":[125,147],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/OpenBlatam/TruthGPT-chatGPT/blob/b3fb5b20557c874b2139e7b7d9318f349d3a4fbe/TruthGPT/Without-Framework/Production/pytorch-main/torch/fx/graph.py"},{"path":"pytorch/torch/_meta_registrations.py","repository":{"id":"R_kgDOOsEsGg","isFork":false,"isPrivate":false,"nameWithOwner":"netanelcyber/zenday1","url":"https://github.com/netanelcyber/zenday1"},"sha":"8ed304872248053d2a82e848d63de1cda629a842","textMatches":[{"fragment":"            torch.float8_e5m2,\n            torch.float8_e4m3fnuz,\n            torch.float8_e5m2fnuz,\n            torch.float4_e2m1fn_x2,\n        )\n\n    torch._check(","matches":[{"indices":[113,135],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/netanelcyber/zenday1/blob/59eaf2b345eda98ad42bb3fc10c0fdbd7f45215c/pytorch/torch/_meta_registrations.py"},{"path":"TruthGPT/Without-Framework/Production/pytorch-main/torch/_meta_registrations.py","repository":{"id":"R_kgDOJBRaWQ","isFork":false,"isPrivate":false,"nameWithOwner":"OpenBlatam/TruthGPT-chatGPT","url":"https://github.com/OpenBlatam/TruthGPT-chatGPT"},"sha":"8ed304872248053d2a82e848d63de1cda629a842","textMatches":[{"fragment":"            torch.float8_e5m2,\n            torch.float8_e4m3fnuz,\n            torch.float8_e5m2fnuz,\n            torch.float4_e2m1fn_x2,\n        )\n\n    torch._check(","matches":[{"indices":[113,135],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/OpenBlatam/TruthGPT-chatGPT/blob/b3fb5b20557c874b2139e7b7d9318f349d3a4fbe/TruthGPT/Without-Framework/Production/pytorch-main/torch/_meta_registrations.py"},{"path":"torch/_tensor_str.py","repository":{"id":"R_kgDOOdu8Yw","isFork":false,"isPrivate":false,"nameWithOwner":"Divigroup-RAP/PYTORCH","url":"https://github.com/Divigroup-RAP/PYTORCH"},"sha":"a03c4efc15b7eb8fa40983ca612ce0709b4f3361","textMatches":[{"fragment":"                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            if tensor.dtype == torch.float4_e2m1fn_x2:  # type: ignore[attr-defined]\n                # torch.float4_e2m1fn_x2 is special and does not support the casts necessary\n                # to print it, we choose to display the uint8 representation here for\n                # convenience of being able to print a tensor.","matches":[{"indices":[115,137],"text":"torch.float4_e2m1fn_x2"},{"indices":[187,209],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/Divigroup-RAP/PYTORCH/blob/ca017bbcb87e44a379c9f6beb3bf68a8177e1872/torch/_tensor_str.py"},{"path":"torch/_tensor_str.py","repository":{"id":"R_kgDOO_BySw","isFork":false,"isPrivate":false,"nameWithOwner":"glen-amd/rocm_pytorch","url":"https://github.com/glen-amd/rocm_pytorch"},"sha":"a03c4efc15b7eb8fa40983ca612ce0709b4f3361","textMatches":[{"fragment":"                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            if tensor.dtype == torch.float4_e2m1fn_x2:  # type: ignore[attr-defined]\n                # torch.float4_e2m1fn_x2 is special and does not support the casts necessary\n                # to print it, we choose to display the uint8 representation here for\n                # convenience of being able to print a tensor.","matches":[{"indices":[115,137],"text":"torch.float4_e2m1fn_x2"},{"indices":[187,209],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/glen-amd/rocm_pytorch/blob/0a6e1d6b9bf78d690a812e4334939e7701bfa794/torch/_tensor_str.py"},{"path":"pytorch/torch/_tensor_str.py","repository":{"id":"R_kgDOOsEsGg","isFork":false,"isPrivate":false,"nameWithOwner":"netanelcyber/zenday1","url":"https://github.com/netanelcyber/zenday1"},"sha":"a03c4efc15b7eb8fa40983ca612ce0709b4f3361","textMatches":[{"fragment":"                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            if tensor.dtype == torch.float4_e2m1fn_x2:  # type: ignore[attr-defined]\n                # torch.float4_e2m1fn_x2 is special and does not support the casts necessary\n                # to print it, we choose to display the uint8 representation here for\n                # convenience of being able to print a tensor.","matches":[{"indices":[115,137],"text":"torch.float4_e2m1fn_x2"},{"indices":[187,209],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/netanelcyber/zenday1/blob/59eaf2b345eda98ad42bb3fc10c0fdbd7f45215c/pytorch/torch/_tensor_str.py"},{"path":"TruthGPT/Without-Framework/Production/pytorch-main/torch/_tensor_str.py","repository":{"id":"R_kgDOJBRaWQ","isFork":false,"isPrivate":false,"nameWithOwner":"OpenBlatam/TruthGPT-chatGPT","url":"https://github.com/OpenBlatam/TruthGPT-chatGPT"},"sha":"a03c4efc15b7eb8fa40983ca612ce0709b4f3361","textMatches":[{"fragment":"                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            if tensor.dtype == torch.float4_e2m1fn_x2:  # type: ignore[attr-defined]\n                # torch.float4_e2m1fn_x2 is special and does not support the casts necessary\n                # to print it, we choose to display the uint8 representation here for\n                # convenience of being able to print a tensor.","matches":[{"indices":[115,137],"text":"torch.float4_e2m1fn_x2"},{"indices":[187,209],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/OpenBlatam/TruthGPT-chatGPT/blob/b3fb5b20557c874b2139e7b7d9318f349d3a4fbe/TruthGPT/Without-Framework/Production/pytorch-main/torch/_tensor_str.py"},{"path":"torch/_tensor_str.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"921e97be233ad18e6beea5ee50f4b809506c60ea","textMatches":[{"fragment":"                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            if tensor.dtype == torch.float4_e2m1fn_x2:  # type: ignore[attr-defined]\n                # torch.float4_e2m1fn_x2 is special and does not support the casts necessary\n                # to print it, we choose to display the uint8 representation here for\n                # convenience of being able to print a tensor.","matches":[{"indices":[115,137],"text":"torch.float4_e2m1fn_x2"},{"indices":[187,209],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/_tensor_str.py"},{"path":"torch/onnx/ops/__init__.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"3bdcd417e1acd6b502ef7071289ebb6d913ec2fc","textMatches":[{"fragment":"    torch.float8_e5m2fnuz: 20,  # FLOAT8E5M2FNUZ\n    # 21 = UINT4\n    # 22 = INT4\n    torch.float4_e2m1fn_x2: 23,  # FLOAT4E2M1\n}\n\n","matches":[{"indices":[86,108],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/onnx/ops/__init__.py"},{"path":"torch/onnx/_internal/exporter/_core.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"fcaa63f04d470ea8310a19d48c63e766e4c656d9","textMatches":[{"fragment":"    torch.float8_e5m2fnuz: ir.DataType.FLOAT8E5M2FNUZ,\n    torch.float4_e2m1fn_x2: ir.DataType.FLOAT4E2M1,\n    torch.int16: ir.DataType.INT16,","matches":[{"indices":[59,81],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # Pass the tensor as the raw data to ir.Tensor's constructor\n        if tensor.dtype == torch.float4_e2m1fn_x2:\n            # Change the shape to the unpacked shape","matches":[{"indices":[96,118],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/onnx/_internal/exporter/_core.py"},{"path":"torch/onnx/_internal/exporter/_dispatching.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"141cb76deacd1cab7d3ebe79045fce42227b8e1e","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: ir.DataType.FLOAT8E4M3FNUZ,\n    torch.float8_e5m2: ir.DataType.FLOAT8E5M2,\n    torch.float8_e5m2fnuz: ir.DataType.FLOAT8E5M2FNUZ,\n    torch.float4_e2m1fn_x2: ir.DataType.FLOAT4E2M1,\n    torch.int16: ir.DataType.INT16,\n    torch.int32: ir.DataType.INT32,\n    torch.int64: ir.DataType.INT64,","matches":[{"indices":[161,183],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/torch/onnx/_internal/exporter/_dispatching.py"},{"path":"torch/onnx/_internal/exporter/_dispatching.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"141cb76deacd1cab7d3ebe79045fce42227b8e1e","textMatches":[{"fragment":"    torch.float8_e4m3fnuz: ir.DataType.FLOAT8E4M3FNUZ,\n    torch.float8_e5m2: ir.DataType.FLOAT8E5M2,\n    torch.float8_e5m2fnuz: ir.DataType.FLOAT8E5M2FNUZ,\n    torch.float4_e2m1fn_x2: ir.DataType.FLOAT4E2M1,\n    torch.int16: ir.DataType.INT16,\n    torch.int32: ir.DataType.INT32,\n    torch.int64: ir.DataType.INT64,","matches":[{"indices":[161,183],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/onnx/_internal/exporter/_dispatching.py"},{"path":"torch/storage.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"e651bc9d16eb181bc61903da197ce7e6ce3395bd","textMatches":[{"fragment":"        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fnuz,\n        torch.float8_e8m0fnu,\n        torch.float4_e2m1fn_x2,\n        torch.bits8,\n        torch.bits16,\n        torch.bits1x8,","matches":[{"indices":[100,122],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/storage.py"},{"path":"torch/storage.py","repository":{"id":"R_kgDOOdu8Yw","isFork":false,"isPrivate":false,"nameWithOwner":"Divigroup-RAP/PYTORCH","url":"https://github.com/Divigroup-RAP/PYTORCH"},"sha":"824a29af59702bb203e189b29ba34a239a22ba63","textMatches":[{"fragment":"        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fnuz,\n        torch.float8_e8m0fnu,\n        torch.float4_e2m1fn_x2,\n        torch.bits8,\n        torch.bits16,\n        torch.bits1x8,","matches":[{"indices":[100,122],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/Divigroup-RAP/PYTORCH/blob/ca017bbcb87e44a379c9f6beb3bf68a8177e1872/torch/storage.py"},{"path":"torch/storage.py","repository":{"id":"R_kgDOO_BySw","isFork":false,"isPrivate":false,"nameWithOwner":"glen-amd/rocm_pytorch","url":"https://github.com/glen-amd/rocm_pytorch"},"sha":"824a29af59702bb203e189b29ba34a239a22ba63","textMatches":[{"fragment":"        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fnuz,\n        torch.float8_e8m0fnu,\n        torch.float4_e2m1fn_x2,\n        torch.bits8,\n        torch.bits16,\n        torch.bits1x8,","matches":[{"indices":[100,122],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/glen-amd/rocm_pytorch/blob/0a6e1d6b9bf78d690a812e4334939e7701bfa794/torch/storage.py"},{"path":"pytorch/torch/storage.py","repository":{"id":"R_kgDOOsEsGg","isFork":false,"isPrivate":false,"nameWithOwner":"netanelcyber/zenday1","url":"https://github.com/netanelcyber/zenday1"},"sha":"824a29af59702bb203e189b29ba34a239a22ba63","textMatches":[{"fragment":"        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fnuz,\n        torch.float8_e8m0fnu,\n        torch.float4_e2m1fn_x2,\n        torch.bits8,\n        torch.bits16,\n        torch.bits1x8,","matches":[{"indices":[100,122],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/netanelcyber/zenday1/blob/59eaf2b345eda98ad42bb3fc10c0fdbd7f45215c/pytorch/torch/storage.py"},{"path":"TruthGPT/Without-Framework/Production/pytorch-main/torch/storage.py","repository":{"id":"R_kgDOJBRaWQ","isFork":false,"isPrivate":false,"nameWithOwner":"OpenBlatam/TruthGPT-chatGPT","url":"https://github.com/OpenBlatam/TruthGPT-chatGPT"},"sha":"824a29af59702bb203e189b29ba34a239a22ba63","textMatches":[{"fragment":"        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fnuz,\n        torch.float8_e8m0fnu,\n        torch.float4_e2m1fn_x2,\n        torch.bits8,\n        torch.bits16,\n        torch.bits1x8,","matches":[{"indices":[100,122],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/OpenBlatam/TruthGPT-chatGPT/blob/b3fb5b20557c874b2139e7b7d9318f349d3a4fbe/TruthGPT/Without-Framework/Production/pytorch-main/torch/storage.py"},{"path":"torch/onnx/_internal/exporter/_type_casting.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"7f2141fe577e64a8d98b6f44100971a03338d8d7","textMatches":[{"fragment":"    \"\"\"Convert a float4x2 tensor to unpacked uint8 np array.\"\"\"\n    assert tensor.dtype == torch.float4_e2m1fn_x2\n    data = tensor.view(torch.uint8).numpy(force=True).flatten()","matches":[{"indices":[91,113],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    \"\"\"\n    assert tensor.dtype == torch.float4_e2m1fn_x2\n    return (*tensor.shape[:-1], tensor.shape[-1] * 2)","matches":[{"indices":[35,57],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/torch/onnx/_internal/exporter/_type_casting.py"},{"path":"TruthGPT/Without-Framework/Production/pytorch-main/test/test_matmul_cuda.py","repository":{"id":"R_kgDOJBRaWQ","isFork":false,"isPrivate":false,"nameWithOwner":"OpenBlatam/TruthGPT-chatGPT","url":"https://github.com/OpenBlatam/TruthGPT-chatGPT"},"sha":"33055b66011f452afc0d1c164b4da2536c4e1492","textMatches":[{"fragment":"F8E8M0_EXP_BIAS = 127\n# exponent and mantissa bits of `torch.float4_e2m1fn_x2`\nFP4_EBITS, FP4_MBITS = 2, 1","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    x = pack_uint4(x)\n    x = x.view(torch.float4_e2m1fn_x2)\n    return x","matches":[{"indices":[37,59],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/OpenBlatam/TruthGPT-chatGPT/blob/b3fb5b20557c874b2139e7b7d9318f349d3a4fbe/TruthGPT/Without-Framework/Production/pytorch-main/test/test_matmul_cuda.py"},{"path":"test/onnx/exporter/test_core.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"7a2eaaf1a82805906fd3340bae011f8cc7e5cb47","textMatches":[{"fragment":"            (torch.uint8, np.uint8),\n            (torch.float4_e2m1fn_x2, ml_dtypes.float4_e2m1fn),\n        ],","matches":[{"indices":[50,72],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    def test_numpy_returns_correct_dtype(self, dtype: torch.dtype, np_dtype):\n        if dtype == torch.float4_e2m1fn_x2:\n            tensor = _core.TorchTensor(torch.tensor([1], dtype=torch.uint8).view(dtype))","matches":[{"indices":[98,120],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/test/onnx/exporter/test_core.py"},{"path":"test/onnx/exporter/test_core.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"7a2eaaf1a82805906fd3340bae011f8cc7e5cb47","textMatches":[{"fragment":"            (torch.uint8, np.uint8),\n            (torch.float4_e2m1fn_x2, ml_dtypes.float4_e2m1fn),\n        ],","matches":[{"indices":[50,72],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    def test_numpy_returns_correct_dtype(self, dtype: torch.dtype, np_dtype):\n        if dtype == torch.float4_e2m1fn_x2:\n            tensor = _core.TorchTensor(torch.tensor([1], dtype=torch.uint8).view(dtype))","matches":[{"indices":[98,120],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/test/onnx/exporter/test_core.py"},{"path":"test/test_matmul_cuda.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"e8b4d9092cdd04c10837ddc4aeda6d2120f10aeb","textMatches":[{"fragment":"F8E8M0_EXP_BIAS = 127\n# exponent and mantissa bits of `torch.float4_e2m1fn_x2`\nFP4_EBITS, FP4_MBITS = 2, 1","matches":[{"indices":[55,77],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"    x = pack_uint4(x)\n    x = x.view(torch.float4_e2m1fn_x2)\n    return x","matches":[{"indices":[37,59],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/test/test_matmul_cuda.py"},{"path":"test/quantization/core/experimental/test_floatx.py","repository":{"id":"MDEwOlJlcG9zaXRvcnkzOTgzNzExMDU=","isFork":false,"isPrivate":true,"nameWithOwner":"pytorch/pytorch-canary","url":"https://github.com/pytorch/pytorch-canary"},"sha":"01f59d4765b7b258e7506be7c7b7ba339666c6ff","textMatches":[{"fragment":"        # can create a tensor of dtype float4\n        x1 = torch.empty(4096, 4096, device=device, dtype=torch.float4_e2m1fn_x2)\n","matches":[{"indices":[104,126],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # can view uint8 as float4_e2m1fn_x2\n        x2.view(torch.float4_e2m1fn_x2)\n","matches":[{"indices":[61,83],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/pytorch/pytorch-canary/blob/c942fda8498152fa842879532c82d7c7c1d8fac7/test/quantization/core/experimental/test_floatx.py"},{"path":"test/quantization/core/experimental/test_floatx.py","repository":{"id":"R_kgDOOdu8Yw","isFork":false,"isPrivate":false,"nameWithOwner":"Divigroup-RAP/PYTORCH","url":"https://github.com/Divigroup-RAP/PYTORCH"},"sha":"01f59d4765b7b258e7506be7c7b7ba339666c6ff","textMatches":[{"fragment":"        # can create a tensor of dtype float4\n        x1 = torch.empty(4096, 4096, device=device, dtype=torch.float4_e2m1fn_x2)\n","matches":[{"indices":[104,126],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # can view uint8 as float4_e2m1fn_x2\n        x2.view(torch.float4_e2m1fn_x2)\n","matches":[{"indices":[61,83],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/Divigroup-RAP/PYTORCH/blob/ca017bbcb87e44a379c9f6beb3bf68a8177e1872/test/quantization/core/experimental/test_floatx.py"},{"path":"test/quantization/core/experimental/test_floatx.py","repository":{"id":"R_kgDOO_BySw","isFork":false,"isPrivate":false,"nameWithOwner":"glen-amd/rocm_pytorch","url":"https://github.com/glen-amd/rocm_pytorch"},"sha":"01f59d4765b7b258e7506be7c7b7ba339666c6ff","textMatches":[{"fragment":"        # can create a tensor of dtype float4\n        x1 = torch.empty(4096, 4096, device=device, dtype=torch.float4_e2m1fn_x2)\n","matches":[{"indices":[104,126],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # can view uint8 as float4_e2m1fn_x2\n        x2.view(torch.float4_e2m1fn_x2)\n","matches":[{"indices":[61,83],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/glen-amd/rocm_pytorch/blob/0a6e1d6b9bf78d690a812e4334939e7701bfa794/test/quantization/core/experimental/test_floatx.py"},{"path":"test/quantization/core/experimental/test_floatx.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"01f59d4765b7b258e7506be7c7b7ba339666c6ff","textMatches":[{"fragment":"        # can create a tensor of dtype float4\n        x1 = torch.empty(4096, 4096, device=device, dtype=torch.float4_e2m1fn_x2)\n","matches":[{"indices":[104,126],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # can view uint8 as float4_e2m1fn_x2\n        x2.view(torch.float4_e2m1fn_x2)\n","matches":[{"indices":[61,83],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/test/quantization/core/experimental/test_floatx.py"},{"path":"pytorch/test/quantization/core/experimental/test_floatx.py","repository":{"id":"R_kgDOOsEsGg","isFork":false,"isPrivate":false,"nameWithOwner":"netanelcyber/zenday1","url":"https://github.com/netanelcyber/zenday1"},"sha":"01f59d4765b7b258e7506be7c7b7ba339666c6ff","textMatches":[{"fragment":"        # can create a tensor of dtype float4\n        x1 = torch.empty(4096, 4096, device=device, dtype=torch.float4_e2m1fn_x2)\n","matches":[{"indices":[104,126],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # can view uint8 as float4_e2m1fn_x2\n        x2.view(torch.float4_e2m1fn_x2)\n","matches":[{"indices":[61,83],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/netanelcyber/zenday1/blob/59eaf2b345eda98ad42bb3fc10c0fdbd7f45215c/pytorch/test/quantization/core/experimental/test_floatx.py"},{"path":"TruthGPT/Without-Framework/Production/pytorch-main/test/quantization/core/experimental/test_floatx.py","repository":{"id":"R_kgDOJBRaWQ","isFork":false,"isPrivate":false,"nameWithOwner":"OpenBlatam/TruthGPT-chatGPT","url":"https://github.com/OpenBlatam/TruthGPT-chatGPT"},"sha":"01f59d4765b7b258e7506be7c7b7ba339666c6ff","textMatches":[{"fragment":"        # can create a tensor of dtype float4\n        x1 = torch.empty(4096, 4096, device=device, dtype=torch.float4_e2m1fn_x2)\n","matches":[{"indices":[104,126],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"},{"fragment":"        # can view uint8 as float4_e2m1fn_x2\n        x2.view(torch.float4_e2m1fn_x2)\n","matches":[{"indices":[61,83],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/OpenBlatam/TruthGPT-chatGPT/blob/b3fb5b20557c874b2139e7b7d9318f349d3a4fbe/TruthGPT/Without-Framework/Production/pytorch-main/test/quantization/core/experimental/test_floatx.py"},{"path":"test/onnx/exporter/test_small_models_e2e.py","repository":{"id":"R_kgDOPBSn6w","isFork":false,"isPrivate":false,"nameWithOwner":"ALonelySheep/CodexPlayground","url":"https://github.com/ALonelySheep/CodexPlayground"},"sha":"f774104af1871a6fd32314c74ea603f81e97264b","textMatches":[{"fragment":"    def test_float4_support(self):\n        class Float4Module(torch.nn.Module):\n            def forward(self):\n                return torch.empty([1], dtype=torch.float4_e2m1fn_x2)\n\n        onnx_program = self.export(Float4Module(), optimize=False)\n        output = onnx_program.model.graph.outputs[0]","matches":[{"indices":[157,179],"text":"torch.float4_e2m1fn_x2"}],"property":"content","type":"FileContent"}],"url":"https://github.com/ALonelySheep/CodexPlayground/blob/26f7ca39724ff43b7b1e22190feeea67d2212f2d/test/onnx/exporter/test_small_models_e2e.py"}]
